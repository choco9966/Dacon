{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #Analysis \n",
    "import matplotlib.pyplot as plt #Visulization\n",
    "import seaborn as sns #Visulization\n",
    "import numpy as np #Analysis \n",
    "from scipy.stats import norm #Analysis \n",
    "from sklearn.preprocessing import StandardScaler #Analysis \n",
    "from scipy import stats #Analysis \n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import gc\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "test_idx = test['key']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 전처리 준비작업\n",
    "- 인천 수정\n",
    "- Validation 구축"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "인천의 경우 서울보다는 부산에 가까워서 city를 부산으로 수정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.loc[test['key']==1503614,'city'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터가 시간의 순서대로 이루어져 있어서 Merge과정에서 순서가 깨지지 않도록 index컬럼을 생성해서 sort작업을 진행해줄것임. \n",
    "- 이를 안해주면 fold에서 다른 cv값이 나옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "train_len = train.shape[0]\n",
    "df_all = pd.concat([train,test])\n",
    "\n",
    "index = []\n",
    "for i in range(0,df_all.shape[0]):\n",
    "    index.append(i)\n",
    "df_all['index'] = index\n",
    "\n",
    "train = df_all[:train_len].reset_index(drop=True)\n",
    "df_test = df_all[train_len:].reset_index(drop=True)\n",
    "\n",
    "df_train_busan = train[train['city']==0]\n",
    "df_test_busan = df_test[df_test['city']==0]\n",
    "df_train_seoul = train[train['city']==1]\n",
    "df_test_seoul = df_test[df_test['city']==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "신뢰성 있는 Validation 구축을 위해서 아파트 별로 가장 마지막 거래를 Validation으로 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "busan_val_idx = df_train_busan.groupby(['apartment_id']).tail(1).index\n",
    "busan_valid = df_train_busan.loc[busan_val_idx,:]\n",
    "busan_valid = busan_valid[['key','transaction_real_price']]\n",
    "\n",
    "seoul_val_idx = df_train_seoul.groupby(['apartment_id']).tail(1).index\n",
    "seoul_valid = df_train_seoul.loc[seoul_val_idx,:]\n",
    "seoul_valid = seoul_valid[['key','transaction_real_price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df_train_busan,df_train_seoul,df_test_busan,df_test_seoul\n",
    "del df_test,train,df_all\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 전처리\n",
    "- 트레인은 날짜가 고른 반면, 테스트는 2018년도 6월 이후가 압도적으로 많음. 샘플링 작업이 필요.\n",
    "- 방과 화장실 0인 값 대체 : 동일한 아파트에서 비슷한 크기에 값이 존재하면 그로 채워넣고, 그렇지 않으면 비슷한 크기에서 median으로 채워 넣음. \n",
    "- 방과 화장실 결측치 대체 : 동일한 아파트에서 비슷한 크기에 값이 존재하면 그로 채워넣고, 그렇지 않으면 비슷한 크기에서 median으로 채워 넣음. \n",
    "- 주차장의 결측치는 0으로 대체\n",
    "- 난방과 현관구조는 None으로 대체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "test_idx = test['key']\n",
    "test.loc[test['key']==1503614,'city'] = 0\n",
    "\n",
    "train_up1 = train[train['transaction_year_month']>201806]\n",
    "train_up1['transaction_real_price'] = train_up1['transaction_real_price'] + 10000000\n",
    "\n",
    "train_up2 = train[train['transaction_year_month']>201806]\n",
    "train_up2['transaction_real_price'] = train_up2['transaction_real_price'] + 5000000\n",
    "\n",
    "train = pd.concat([train,train_up1])\n",
    "train = pd.concat([train,train_up2])\n",
    "train = train.reset_index(drop=True)\n",
    "del train_up1,train_up2\n",
    "gc.collect()\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "train_len = train.shape[0]\n",
    "df_all = pd.concat([train,test])\n",
    "\n",
    "index = []\n",
    "for i in range(0,df_all.shape[0]):\n",
    "    index.append(i)\n",
    "df_all['index'] = index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 0인 값 대체\n",
    "df_all.loc[(df_all['apartment_id']==2805) & (df_all['supply_area'] > 90),'room_count'] = 3\n",
    "df_all.loc[(df_all['apartment_id']==2805) & (df_all['supply_area'] > 90),'bathroom_count'] = 2\n",
    "\n",
    "df_all.loc[(df_all['apartment_id']==895) & (df_all['supply_area'] > 137),'room_count'] = 4\n",
    "df_all.loc[(df_all['apartment_id']==895) & (df_all['supply_area'] > 137),'bathroom_count'] = 2\n",
    "\n",
    "df_all.loc[(df_all['apartment_id']==903) & (df_all['supply_area'] > 135),'room_count'] = 4\n",
    "df_all.loc[(df_all['apartment_id']==903) & (df_all['supply_area'] > 135),'bathroom_count'] = 2\n",
    "\n",
    "df_all.loc[(df_all['apartment_id']==1622) & (df_all['supply_area'] == 127.07),'room_count'] = 4\n",
    "df_all.loc[(df_all['apartment_id']==1622) & (df_all['supply_area'] == 127.07),'bathroom_count'] = 2\n",
    "\n",
    "df_all.loc[(df_all['apartment_id']==14029) & (df_all['supply_area'] > 100),'room_count'] = 3\n",
    "df_all.loc[(df_all['apartment_id']==14029) & (df_all['supply_area'] > 100),'bathroom_count'] = 1\n",
    "\n",
    "df_all.loc[(df_all['apartment_id']==14029) & (df_all['supply_area'] < 100),'room_count'] = 2\n",
    "df_all.loc[(df_all['apartment_id']==14029) & (df_all['supply_area'] < 100),'bathroom_count'] = 1\n",
    "\n",
    "df_all.loc[(df_all['apartment_id']==12067) & (df_all['supply_area'] >= 95),'room_count'] = 3\n",
    "df_all.loc[(df_all['apartment_id']==12067) & (df_all['supply_area'] >= 95),'bathroom_count'] = 2\n",
    "\n",
    "df_all.loc[(df_all['apartment_id']==12067) & (df_all['supply_area'] == 92),'room_count'] = 3\n",
    "df_all.loc[(df_all['apartment_id']==12067) & (df_all['supply_area'] == 92),'bathroom_count'] = 1\n",
    "\n",
    "df_all.loc[(df_all['apartment_id']==12067) & (df_all['supply_area'] < 90),'room_count'] = 2\n",
    "df_all.loc[(df_all['apartment_id']==12067) & (df_all['supply_area'] < 90),'bathroom_count'] = 1\n",
    "\n",
    "df_all.loc[(df_all['apartment_id']==360) & (df_all['supply_area'] == 189.99),'room_count'] = 5\n",
    "df_all.loc[(df_all['apartment_id']==360) & (df_all['supply_area'] == 189.99),'bathroom_count'] = 2\n",
    "\n",
    "df_all.loc[(df_all['apartment_id']==360) & (df_all['supply_area'] == 154.46),'room_count'] = 4\n",
    "df_all.loc[(df_all['apartment_id']==360) & (df_all['supply_area'] == 154.46),'bathroom_count'] = 2\n",
    "\n",
    "df_all.loc[(df_all['apartment_id']==568) & (df_all['supply_area']//10 == 11.0),'room_count'] = 3\n",
    "df_all.loc[(df_all['apartment_id']==568) & (df_all['supply_area']//10 == 11.0),'bathroom_count'] = 1\n",
    "\n",
    "df_all.loc[(df_all['apartment_id']==1543) & (df_all['supply_area'] > 150 ),'room_count'] = 4\n",
    "df_all.loc[(df_all['apartment_id']==1543) & (df_all['supply_area'] > 150),'bathroom_count'] = 2\n",
    "\n",
    "df_all.loc[(df_all['apartment_id']==618) & (df_all['supply_area'] == 92.94),'room_count'] = 3\n",
    "df_all.loc[(df_all['apartment_id']==618) & (df_all['supply_area'] == 92.94),'bathroom_count'] = 1\n",
    "\n",
    "df_all.loc[(df_all['apartment_id']==618) & (df_all['supply_area'] == 110.57),'room_count'] = 3\n",
    "df_all.loc[(df_all['apartment_id']==618) & (df_all['supply_area'] == 110.57),'bathroom_count'] = 1\n",
    "\n",
    "df_all.loc[(df_all['apartment_id']==4368) & (df_all['supply_area'] > 90),'room_count'] = 3\n",
    "df_all.loc[(df_all['apartment_id']==4368) & (df_all['supply_area'] > 90),'bathroom_count'] = 1\n",
    "\n",
    "df_all.loc[(df_all['apartment_id']==4368) & (df_all['supply_area'] < 90),'room_count'] = 2\n",
    "df_all.loc[(df_all['apartment_id']==4368) & (df_all['supply_area'] < 90),'bathroom_count'] = 1\n",
    "\n",
    "df_all.loc[(df_all['apartment_id']==3701) & (df_all['supply_area'] == 148.55),'room_count'] = 4\n",
    "df_all.loc[(df_all['apartment_id']==3701) & (df_all['supply_area'] == 148.55),'bathroom_count'] = 2\n",
    "\n",
    "df_all.loc[(df_all['apartment_id']==346) & (df_all['supply_area'] > 100),'room_count'] = 3\n",
    "df_all.loc[(df_all['apartment_id']==346) & (df_all['supply_area'] > 100),'bathroom_count'] = 2\n",
    "\n",
    "df_all.loc[(df_all['apartment_id']==1524) & (df_all['supply_area'] == 104.39),'room_count'] = 3\n",
    "df_all.loc[(df_all['apartment_id']==1524) & (df_all['supply_area'] == 104.39),'bathroom_count'] = 2\n",
    "\n",
    "df_all.loc[(df_all['apartment_id']==1524) & (df_all['supply_area'] == 175.60),'room_count'] = 5\n",
    "df_all.loc[(df_all['apartment_id']==1524) & (df_all['supply_area'] == 175.60),'bathroom_count'] = 2\n",
    "\n",
    "df_all.loc[(df_all['apartment_id']==431) & (df_all['supply_area']//10 == 9.0),'room_count'] = 3\n",
    "df_all.loc[(df_all['apartment_id']==431) & (df_all['supply_area']//10 == 9.0),'bathroom_count'] = 1\n",
    "\n",
    "df_all.loc[(df_all['apartment_id']==431) & (df_all['supply_area']//10 == 10.0),'room_count'] = 3\n",
    "df_all.loc[(df_all['apartment_id']==431) & (df_all['supply_area']//10 == 10.0),'bathroom_count'] = 2\n",
    "\n",
    "df_all.loc[(df_all['apartment_id']==431) & (df_all['supply_area']//10 == 13.0),'room_count'] = 4\n",
    "df_all.loc[(df_all['apartment_id']==431) & (df_all['supply_area']//10 == 13.0),'bathroom_count'] = 2\n",
    "\n",
    "df_all.loc[(df_all['apartment_id']==431) & (df_all['supply_area']//10 == 14.0),'room_count'] = 4\n",
    "df_all.loc[(df_all['apartment_id']==431) & (df_all['supply_area']//10 == 14.0),'bathroom_count'] = 2\n",
    "\n",
    "df_all.loc[(df_all['apartment_id']==1112) & (df_all['supply_area']//10 == 7.0),'room_count'] = 3\n",
    "df_all.loc[(df_all['apartment_id']==1112) & (df_all['supply_area']//10 == 7.0),'bathroom_count'] = 1\n",
    "\n",
    "df_all.loc[(df_all['apartment_id']==65) & (df_all['supply_area']//10 == 11.0),'room_count'] = 3\n",
    "df_all.loc[(df_all['apartment_id']==65) & (df_all['supply_area']//10 == 11.0),'bathroom_count'] = 1\n",
    "\n",
    "df_all.loc[(df_all['apartment_id']==541) & (df_all['supply_area']//10 == 8.0),'room_count'] = 2\n",
    "df_all.loc[(df_all['apartment_id']==541) & (df_all['supply_area']//10 == 8.0),'bathroom_count'] = 1\n",
    "\n",
    "df_all.loc[(df_all['apartment_id']==184) & (df_all['supply_area'] == 66.12),'room_count'] = 2\n",
    "df_all.loc[(df_all['apartment_id']==184) & (df_all['supply_area'] == 66.12),'bathroom_count'] = 1\n",
    "\n",
    "df_all.loc[(df_all['apartment_id']==2601) & (df_all['supply_area'] == 104.97),'room_count'] = 3\n",
    "df_all.loc[(df_all['apartment_id']==2601) & (df_all['supply_area'] == 104.97),'bathroom_count'] = 2\n",
    "\n",
    "df_all.loc[(df_all['apartment_id']==6161) & (df_all['supply_area'] == 99.91),'room_count'] = 3\n",
    "df_all.loc[(df_all['apartment_id']==6161) & (df_all['supply_area'] == 99.91),'bathroom_count'] = 2\n",
    "\n",
    "df_all.loc[(df_all['apartment_id']==3685) & (df_all['supply_area'] == 115.70),'room_count'] = 3\n",
    "df_all.loc[(df_all['apartment_id']==3685) & (df_all['supply_area'] == 115.70),'bathroom_count'] = 2\n",
    "\n",
    "df_all.loc[(df_all['apartment_id']==21288) & (df_all['supply_area'] == 116.03),'room_count'] = 3\n",
    "df_all.loc[(df_all['apartment_id']==21288) & (df_all['supply_area'] == 116.03),'bathroom_count'] = 1\n",
    "\n",
    "df_all.loc[(df_all['apartment_id']==10636) & (df_all['supply_area'] == 112.40),'room_count'] = 3\n",
    "df_all.loc[(df_all['apartment_id']==10636) & (df_all['supply_area'] == 112.40),'bathroom_count'] = 2\n",
    "\n",
    "df_all.loc[(df_all['apartment_id']==1162) & (df_all['supply_area'] == 154.71),'room_count'] = 4\n",
    "df_all.loc[(df_all['apartment_id']==1162) & (df_all['supply_area'] == 154.71),'bathroom_count'] = 2\n",
    "\n",
    "df_all.loc[(df_all['apartment_id']==10989) & (df_all['supply_area'] == 110.51),'room_count'] = 3\n",
    "df_all.loc[(df_all['apartment_id']==10989) & (df_all['supply_area'] == 110.51),'bathroom_count'] = 2\n",
    "\n",
    "df_all.loc[(df_all['apartment_id']==11096) & (df_all['supply_area'] == 97.09),'room_count'] = 4\n",
    "df_all.loc[(df_all['apartment_id']==11096) & (df_all['supply_area'] == 97.09),'bathroom_count'] = 1\n",
    "\n",
    "df_all.loc[(df_all['apartment_id']==184) & (df_all['supply_area'] == 69.42),'room_count'] = 2\n",
    "df_all.loc[(df_all['apartment_id']==184) & (df_all['supply_area'] == 69.42),'bathroom_count'] = 1\n",
    "\n",
    "df_all.loc[(df_all['apartment_id']==534) & (df_all['supply_area'] //10 == 11.0),'room_count'] = 3\n",
    "df_all.loc[(df_all['apartment_id']==534) & (df_all['supply_area'] //10 == 11.0),'bathroom_count'] = 1\n",
    "\n",
    "df_all.loc[(df_all['apartment_id']==17384) & (df_all['supply_area'] //10 == 11.0),'room_count'] = 3\n",
    "df_all.loc[(df_all['apartment_id']==17384) & (df_all['supply_area'] //10 == 11.0),'bathroom_count'] = 2\n",
    "\n",
    "df_all.loc[(df_all['apartment_id']==431) & (df_all['supply_area'] //10 == 10.0),'room_count'] = 3\n",
    "df_all.loc[(df_all['apartment_id']==431) & (df_all['supply_area'] //10 == 10.0),'bathroom_count'] = 2\n",
    "\n",
    "df_all.loc[(df_all['apartment_id']==4058) & (df_all['supply_area'] //10 == 9.0),'room_count'] = 3\n",
    "df_all.loc[(df_all['apartment_id']==4058) & (df_all['supply_area'] //10 == 9.0),'bathroom_count'] = 2\n",
    "\n",
    "#df_all.loc[(df_all['apartment_id']==1388) & (df_all['room_count']==0)]\n",
    "df_all.loc[(df_all['apartment_id']==1388) & (df_all['supply_area'] //10 == 14.0),'room_count'] = 4\n",
    "df_all.loc[(df_all['apartment_id']==1388) & (df_all['supply_area'] //10 == 14.0),'bathroom_count'] = 2\n",
    "\n",
    "df_all.loc[(df_all['apartment_id']==7136) & (df_all['supply_area'] //10 == 7.0),'room_count'] = 3\n",
    "df_all.loc[(df_all['apartment_id']==7136) & (df_all['supply_area'] //10 == 7.0),'bathroom_count'] = 1\n",
    "\n",
    "#df_all.loc[(df_all['apartment_id']==18737)]\n",
    "df_all.loc[(df_all['apartment_id']==18737) & (df_all['supply_area'] //10 == 17.0),'room_count'] = 3\n",
    "df_all.loc[(df_all['apartment_id']==18737) & (df_all['supply_area'] //10 == 17.0),'bathroom_count'] = 2\n",
    "\n",
    "df_all.loc[(df_all['apartment_id']==18741) & (df_all['supply_area'] >= 160),'room_count'] = 4\n",
    "df_all.loc[(df_all['apartment_id']==18741) & (df_all['supply_area'] >= 160),'bathroom_count'] = 2\n",
    "\n",
    "#df_all.loc[(df_all['apartment_id']==18732)]\n",
    "\n",
    "df_all.loc[(df_all['apartment_id']==18732) & (df_all['supply_area'] //10 == 11.0),'room_count'] = 3\n",
    "df_all.loc[(df_all['apartment_id']==18732) & (df_all['supply_area'] //10 == 11.0),'bathroom_count'] = 2\n",
    "\n",
    "df_all.loc[(df_all['apartment_id']==18732) & (df_all['supply_area'] //10 == 18.0),'room_count'] = 4\n",
    "df_all.loc[(df_all['apartment_id']==18732) & (df_all['supply_area'] //10 == 18.0),'bathroom_count'] = 2\n",
    "\n",
    "df_all.loc[(df_all['apartment_id']==360) & (df_all['supply_area'] //10 == 16.0),'room_count'] = 4\n",
    "df_all.loc[(df_all['apartment_id']==360) & (df_all['supply_area'] //10 == 16.0),'bathroom_count'] = 2\n",
    "\n",
    "df_all.loc[(df_all['apartment_id']==8460) & (df_all['supply_area'] //10 == 8.0),'room_count'] = 3\n",
    "df_all.loc[(df_all['apartment_id']==8460) & (df_all['supply_area'] //10 == 8.0),'bathroom_count'] = 2\n",
    "\n",
    "df_all.loc[(df_all['apartment_id']==6175) & (df_all['supply_area'] > 290),'room_count'] = 5\n",
    "df_all.loc[(df_all['apartment_id']==6175) & (df_all['supply_area'] > 290),'bathroom_count'] = 3\n",
    "\n",
    "df_all.loc[(df_all['apartment_id']==6232)]\n",
    "df_all.loc[(df_all['apartment_id']==6232) & (df_all['supply_area'] //10 == 19.0),'room_count'] = 3\n",
    "df_all.loc[(df_all['apartment_id']==6232) & (df_all['supply_area'] //10 == 19.0),'bathroom_count'] = 2\n",
    "\n",
    "df_all.loc[(df_all['apartment_id']==15502) & (df_all['supply_area'] //10 == 10.0),'room_count'] = 3\n",
    "df_all.loc[(df_all['apartment_id']==15502) & (df_all['supply_area'] //10 == 10.0),'bathroom_count'] = 2\n",
    "\n",
    "df_all.loc[(df_all['apartment_id']==568) & (df_all['supply_area'] //10 == 19.0),'room_count'] = 5\n",
    "df_all.loc[(df_all['apartment_id']==568) & (df_all['supply_area'] //10 == 19.0),'bathroom_count'] = 2\n",
    "\n",
    "df_all.loc[(df_all['apartment_id']==16837) & (df_all['supply_area'] //10 == 9.0),'room_count'] = 3\n",
    "df_all.loc[(df_all['apartment_id']==16837) & (df_all['supply_area'] //10 == 9.0),'bathroom_count'] = 2\n",
    "\n",
    "df_all.loc[(df_all['apartment_id']==37468) & (df_all['supply_area']  <= 200),'room_count'] = 3\n",
    "df_all.loc[(df_all['apartment_id']==37468) & (df_all['supply_area']  <= 200),'bathroom_count'] = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 결측치 대체\n",
    "- 방, 화장실은 위와 동일한 방식으로 채워넣음.\n",
    "- 주차장의 경우 0으로 대체. dacon에 물어본 결과 결측치는 0이라고 했음.\n",
    "- 히트 및 현관의 결측치는 None으로 대체. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 방과 화장실 결측치\n",
    "df_all.loc[df_all['apartment_id'] == 9005, ['room_count']] = 1\n",
    "df_all.loc[df_all['apartment_id'] == 9005, ['bathroom_count']] = 1\n",
    "\n",
    "df_all.loc[df_all['apartment_id'] == 1179, ['room_count']] = 4\n",
    "df_all.loc[df_all['apartment_id'] == 1179, ['bathroom_count']] = 2\n",
    "\n",
    "df_all.loc[df_all['apartment_id'] == 10627, ['room_count']] = 3\n",
    "df_all.loc[df_all['apartment_id'] == 10627, ['bathroom_count']] = 1\n",
    "\n",
    "df_all.loc[(df_all['apartment_id'] == 10627) & (df_all['supply_area'] == 56.61), ['room_count']] = 2\n",
    "df_all.loc[(df_all['apartment_id'] == 10627) & (df_all['supply_area'] == 56.61), ['bathroom_count']] = 1\n",
    "\n",
    "df_all.loc[(df_all['apartment_id'] == 7992) , ['room_count']] = 3\n",
    "df_all.loc[(df_all['apartment_id'] == 7992) & (df_all['supply_area'] <= 81), ['bathroom_count']] = 1\n",
    "df_all.loc[(df_all['apartment_id'] == 7992) & (df_all['supply_area'] > 81), ['bathroom_count']] = 2\n",
    "\n",
    "df_all.loc[(df_all['apartment_id'] == 7118) & (df_all['supply_area'] == 75.55), ['room_count']] = 3\n",
    "df_all.loc[(df_all['apartment_id'] == 7118) & (df_all['supply_area'] == 75.55), ['bathroom_count']] = 1\n",
    "\n",
    "df_all.loc[(df_all['apartment_id'] == 7118) & (df_all['supply_area']//10 == 5.0), ['room_count']] = 2\n",
    "df_all.loc[(df_all['apartment_id'] == 7118) & (df_all['supply_area']//10 == 5.0), ['bathroom_count']] = 1\n",
    "\n",
    "df_all.loc[(df_all['apartment_id'] == 4047) & (df_all['supply_area']//10 == 11.0), ['room_count']] = 3\n",
    "df_all.loc[(df_all['apartment_id'] == 4047) & (df_all['supply_area']//10 == 11.0), ['bathroom_count']] =2\n",
    "\n",
    "df_all.loc[(df_all['apartment_id'] == 37175) & (df_all['supply_area'] < 80), ['room_count']] = 2\n",
    "df_all.loc[(df_all['apartment_id'] == 37175) & (df_all['supply_area'] < 80), ['bathroom_count']] = 1\n",
    "\n",
    "df_all.loc[(df_all['apartment_id'] == 37175) & (df_all['supply_area'] > 80), ['room_count']] = 3\n",
    "df_all.loc[(df_all['apartment_id'] == 37175) & (df_all['supply_area'] > 80), ['bathroom_count']] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 주차장 결측치\n",
    "df_all.loc[(df_all['total_parking_capacity_in_site'].isnull()), ['total_parking_capacity_in_site']] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 히트 결측치\n",
    "df_all.loc[(df_all['heat_type'].isnull()), ['heat_type']] = 'None'\n",
    "df_all.loc[(df_all['heat_fuel'].isnull()), ['heat_fuel']] = 'None'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 현관구조 결측치\n",
    "df_all.loc[(df_all['heat_fuel'].isnull()), ['front_door_structure']] = 'None'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파생변수 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 용적률(容積率)은 건축 용어로 전체 대지면적에 대한 건물 연면적의 비율을 뜻하며 백분율로 표시한다. \n",
    "### 용적률이 높을수록 건축할 수 있는 연면적이 많아져 건축밀도가 높아지므로, 적정 주거환경을 보장하기 위하여 용적률의 상한선을 지정한다.\n",
    "df_all['effective_ratio'] = (df_all['exclusive_use_area'] / df_all['supply_area']) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 시간을 좀 더 세부적으로 나타냄. \n",
    "df_all['transaction_date1'] = df_all.transaction_date.apply(lambda x: x[-2:])\n",
    "#convert int to date\n",
    "df_all['transaction_year_month1'] = df_all['transaction_year_month'].astype(str)\n",
    "#join month and date \n",
    "df_all['transaction_year_month_date'] = df_all[['transaction_year_month1', 'transaction_date1']].apply(lambda x: ''.join(x), axis=1)\n",
    "#convert  month and date to datetime \n",
    "df_all['transaction_year_month_date'] = pd.to_datetime(df_all['transaction_year_month_date'] )\n",
    "#reindext datetime\n",
    "del df_all['transaction_date1']; del df_all['transaction_year_month1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 계산의 편의성을 위해 날짜를 만들어 둠.\n",
    "df_all['year'] = df_all['transaction_year_month_date'].dt.year\n",
    "df_all['month'] = df_all['transaction_year_month_date'].dt.month\n",
    "df_all['month'] = df_all['month'].apply(lambda x : x-1 if x%2 == 0 else x)\n",
    "df_all['mean_year_month'] = df_all['year']*100 + df_all['month']\n",
    "del df_all['year']\n",
    "del df_all['month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 동일한 아파트의 가장 최근의 거래와 현재 거래의 차이를 계산\n",
    "df_all['last_month'] = df_all.groupby(['apartment_id'])['transaction_year_month'].shift(1)\n",
    "df_all['diff_month'] = df_all['transaction_year_month'] - df_all['last_month']\n",
    "del df_all['last_month']\n",
    "\n",
    "### 방의 총 갯수 ( 화장실 + 방 )\n",
    "df_all['total_room'] = df_all['room_count'] + df_all['bathroom_count']\n",
    "\n",
    "### Last_price_1과 3은 동일한 아파트의 면적대비 거래액을 의미. 추가로 현재 면적을 곱해줘야 함. \n",
    "df_all['last_price_1'] = df_all['transaction_real_price']/df_all['exclusive_use_area']\n",
    "df_all['last_price_1'] = df_all.groupby(['apartment_id'])['last_price_1'].shift(1)\n",
    "\n",
    "df_all['last_price_3'] = df_all['transaction_real_price']/df_all['supply_area']\n",
    "df_all['last_price_3'] = df_all.groupby(['apartment_id'])['last_price_3'].shift(1)\n",
    "\n",
    "df_all['last_area'] = df_all.groupby(['apartment_id'])['exclusive_use_area'].shift(1)\n",
    "df_all['last_transaction_year_month'] = df_all.groupby(['apartment_id'])['transaction_year_month'].shift(1)\n",
    "#df_all['transaction_real_price'] = np.log1p(df_all['transaction_real_price'])\n",
    "\n",
    "df_all['last_price_1'] = df_all['last_price_1'] * df_all['exclusive_use_area'] #현재 면적을 곱해줘서 비교를 가능하게 만듬.\n",
    "df_all['last_price_3'] = df_all['last_price_3'] * df_all['supply_area'] #현재 면적을 곱해줘서 비교를 가능하게 만듬.\n",
    "del df_all['last_area'],df_all['last_transaction_year_month']\n",
    "\n",
    "### log를 씌어줘서 정규성을 띄게 만듬. \n",
    "df_all['last_price_1'] = np.log1p(df_all['last_price_1'])\n",
    "df_all['last_price_3'] = np.log1p(df_all['last_price_3'])\n",
    "df_all['transaction_real_price'] = np.log1p(df_all['transaction_real_price'])\n",
    "\n",
    "### 빌딩의 간격계산\n",
    "df_all['difference_building_height'] = df_all['tallest_building_in_sites'] - df_all['lowest_building_in_sites']\n",
    "### 세대당 주차수 계산\n",
    "df_all['capacity_per_household'] = df_all['total_parking_capacity_in_site']/df_all['total_household_count_in_sites']\n",
    "\n",
    "### 아파트당 세대 수 계산\n",
    "df_all['household_per_building'] = df_all['total_household_count_in_sites']/df_all['apartment_building_count_in_sites']\n",
    "\n",
    "### 아파트당 타입의 비율 계산\n",
    "df_all['areahousehold_per_household'] = df_all['total_household_count_of_area_type']/df_all['total_household_count_in_sites']\n",
    "\n",
    "df_all['year'] = df_all['transaction_year_month']//100\n",
    "\n",
    "### 거래된 기간과 완성된 년도의 차이 계산\n",
    "df_all['transaction_diff_completion'] = df_all['transaction_year_month'] - df_all['year_of_completion']\n",
    "\n",
    "### 몇번째 층인지 비율 계산\n",
    "df_all['floor_ratio'] = df_all['floor']/df_all['tallest_building_in_sites']\n",
    "\n",
    "### 재개발 예정인지 가중치 줌. \n",
    "### 35를 상한선으로 잡은것은 이 이상이 되면 재개발 될 거라는 심리가 떨어져서 임.\n",
    "df_all['weight'] = 0\n",
    "df_all.loc[((df_all['year']-df_all['year_of_completion']) >= 25) & ((df_all['year']-df_all['year_of_completion']) < 35) & (df_all['effective_ratio'] >= 80) & (df_all['tallest_building_in_sites'] <=5),'weight'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subway, school 정보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 아래의 파일은 따로 첨부한 코드에 계산식이 나와있습니다.\n",
    "### Apartment_subway : 0.5, 1km내에 몇개의 지하철이 있냐, 몇개의 호선이 있냐\n",
    "### Apartment_gd_hd : 강남 및 해운대로부터의 거리가 얼마나 되냐\n",
    "### apartment_school : 0.5km 내에 초,중,고등학교가 있냐 없냐. total_0.5는 3개 중에서 몇개가 있는지\n",
    "### min_distance_apartment : 가장 가까운 초,중,고,지하철의 거리\n",
    "apartment = pd.read_csv(\"Apartment_subway.csv\")\n",
    "apartment1 = apartment[['apartment_id','subwayline_count_0.5','subwayline_count_1','subway_count_0.5','subway_count_1']]\n",
    "apartment2 = pd.read_csv(\"Apartment_ga_hd.csv\")\n",
    "apartment2 = apartment2[['apartment_id','gangnam_dist']]\n",
    "apartment3 = pd.read_csv(\"apartment_school.csv\")\n",
    "apartment3 = apartment3[['apartment_id','elementary_0.5','middle_0.5','high_0.5','total_0.5']]\n",
    "apartment4 = pd.read_csv(\"min_distance_apartment.csv\")\n",
    "apartment4 = apartment4[['apartment_id','subway_min_distance','min_distance_ele','min_distance_middle','min_distance_high']]\n",
    "#apartment4 = pd.read_csv(\"apartment_bub.csv\")\n",
    "#apartment4 = apartment4[['apartment_id','gu','dong']]\n",
    "df_all = pd.merge(df_all,apartment1,on='apartment_id').reset_index(drop=True)\n",
    "df_all = pd.merge(df_all,apartment2,on='apartment_id').reset_index(drop=True)\n",
    "df_all = pd.merge(df_all,apartment3,on='apartment_id').reset_index(drop=True)\n",
    "df_all = pd.merge(df_all,apartment4,on='apartment_id').reset_index(drop=True).sort_values('index') #index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 공공데이터\n",
    "- 사용목록과 코드는 따로 첨부하였습니다. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### 쇼핑몰\n",
    "busan_shop = pd.read_csv(\"(0119)busan_shop.csv\")\n",
    "busan_shop = busan_shop[['apartment_id','shop_count_0.5','shop_count_1']]\n",
    "df_all = pd.merge(df_all,busan_shop,on='apartment_id').reset_index(drop=True).sort_values('index') #index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df_all.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### 대학교\n",
    "university = pd.read_csv('apartment_public.csv')\n",
    "university = university[['apartment_id','univ_1,2']]\n",
    "df_all = pd.merge(df_all,university,on='apartment_id').reset_index(drop=True).sort_values('index') #index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 구청\n",
    "public = pd.read_csv('apartment_public.csv')\n",
    "public = public[['apartment_id','public_1']]\n",
    "public['public_1'] = public['public_1'].apply(lambda x: 1 if x>1 else x)\n",
    "df_all = pd.merge(df_all,public,on='apartment_id').reset_index(drop=True).sort_values('index') #index"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### 스타벅스\n",
    "coffee = pd.read_csv(\"(0122)starbucks_list.csv\")\n",
    "coffee = coffee[['apartment_id','shop_count_1']]\n",
    "coffee.columns = ['apartment_id','coffee_count_1']\n",
    "df_all = pd.merge(df_all,coffee,on='apartment_id').reset_index(drop=True)\n",
    "#df_all['distance_from_hangang_6.0'] = df_all['distance_from_hangang_6.0'].apply(lambda x: 1 if x >=1 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA, FastICA,NMF,LatentDirichletAllocation,IncrementalPCA,MiniBatchSparsePCA\n",
    "from sklearn.decomposition import TruncatedSVD,FactorAnalysis,KernelPCA\n",
    "\n",
    "train_df = df_all.loc[df_all['transaction_real_price'] != 0]\n",
    "test_df = df_all.loc[df_all['transaction_real_price'] == 0]\n",
    "\n",
    "train_len = train_df.shape[0]\n",
    "\n",
    "### 날짜와 object, 공공데이터는 제거. \n",
    "train_columns = [c for c in train_df.columns if c not in ['key','transaction_real_price','transaction_year_month_date','transaction_date','heat_type','heat_fuel',\n",
    "                                                          'front_door_structure','shop_count_0.5','shop_count_1','univ_1,2','public_1','coffee_count_0.5']]\n",
    "train_columns\n",
    "\n",
    "# PCA\n",
    "n_comp = 1\n",
    "\n",
    "# ICA\n",
    "ica = FastICA(n_components=n_comp, random_state=2019)\n",
    "ica2_results_train = ica.fit_transform(train_df[train_columns].fillna(-1))\n",
    "ica2_results_test = ica.transform(test_df[train_columns].fillna(-1))\n",
    "\n",
    "for i in range(1, n_comp+1):\n",
    "    train_df['ica_' + str(i)] = ica2_results_train[:,i-1]\n",
    "    test_df['ica_' + str(i)] = ica2_results_test[:, i-1]\n",
    "    train_columns.append('ica_' + str(i))\n",
    "\n",
    "df_all = pd.concat([train_df,test_df])\n",
    "df_all = df_all.sort_values('index').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 날짜 형식변경\n",
    "df_all['transaction_date1'] = df_all.transaction_date.apply(lambda x: x[-2:])\n",
    "#convert int to date\n",
    "df_all['transaction_year_month1'] = df_all['transaction_year_month'].astype(str)\n",
    "#join month and date \n",
    "df_all['transaction_year_month_date'] = df_all[['transaction_year_month1', 'transaction_date1']].apply(lambda x: ''.join(x), axis=1)\n",
    "df_all['transaction_year_month_date'] = df_all['transaction_year_month_date'].astype(int)\n",
    "del df_all['transaction_date1']; del df_all['transaction_year_month1']\n",
    "del df_all['transaction_year_month']; del df_all['transaction_date'] ; del df_all['year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### One-hot-encoding\n",
    "df_all = pd.get_dummies(df_all)\n",
    "train = df_all[:train_len]\n",
    "df_test = df_all[train_len:]\n",
    "del df_all\n",
    "train = train.sort_values('index')\n",
    "df_test = df_test.sort_values('index')\n",
    "\n",
    "### 거리의 경우 너무 크면 의미가 없어서 상관관계를 통해서 파악한 16을 기준으로 잘라버림. \n",
    "train['gangnam_dist'] = train['gangnam_dist'].apply(lambda x: 16 if x > 16 else x)\n",
    "df_test['gangnam_dist'] = df_test['gangnam_dist'].apply(lambda x: 16 if x > 16 else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LIGHTGBM 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "excluded_features = [\n",
    "    'transaction_real_price'\n",
    "]\n",
    "\n",
    "categorical_features = [\n",
    "    'apartment_id'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train['mean_year_month']\n",
    "del df_test['mean_year_month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_busan = train[train['city']==0].reset_index(drop=True)\n",
    "df_test_busan = df_test[df_test['city']==0].reset_index(drop=True)\n",
    "df_train_seoul = train[train['city']==1].reset_index(drop=True)\n",
    "df_test_seoul = df_test[df_test['city']==1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 부산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "busan_val_idx = df_train_busan.groupby(['apartment_id']).tail(1).index\n",
    "busan_trx_idx = set(df_train_busan.index).difference(busan_val_idx)\n",
    "busan_train = df_train_busan.loc[busan_trx_idx,:]\n",
    "busan_valid = df_train_busan.loc[busan_val_idx,:]\n",
    "\n",
    "busan_train = busan_train.sort_values('index')\n",
    "busan_valid = busan_valid.sort_values('index')\n",
    "df_test_busan = df_test_busan.sort_values('index')\n",
    "\n",
    "\n",
    "import time\n",
    "\n",
    "y_train = busan_train['transaction_real_price'].reset_index(drop=True)\n",
    "\n",
    "x_train = busan_train.copy().reset_index(drop=True)\n",
    "del x_train['city']; del x_train['transaction_real_price']; del x_train['key']; del x_train['public_1']; \n",
    "\n",
    "excluded_features = ['key','index']\n",
    "train_features = [_f for _f in x_train.columns if _f not in excluded_features]\n",
    "\n",
    "y_valid = busan_valid['transaction_real_price'].reset_index(drop=True)\n",
    "\n",
    "x_valid = busan_valid.copy().reset_index(drop=True)\n",
    "x_valid_key = x_valid['key'].values\n",
    "del x_valid['city']; del x_valid['transaction_real_price']; del x_valid['key']; del x_valid['public_1']; \n",
    "\n",
    "busan_key = df_test_busan['key'].values\n",
    "x_test = df_test_busan[train_features].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 125 rounds.\n",
      "[1000]\ttraining's rmse: 0.0934108\tvalid_1's rmse: 0.097885\n",
      "[2000]\ttraining's rmse: 0.0848274\tvalid_1's rmse: 0.0924123\n",
      "[3000]\ttraining's rmse: 0.079864\tvalid_1's rmse: 0.0885951\n",
      "[4000]\ttraining's rmse: 0.0764913\tvalid_1's rmse: 0.0858297\n",
      "[5000]\ttraining's rmse: 0.073998\tvalid_1's rmse: 0.0835829\n",
      "[6000]\ttraining's rmse: 0.0720416\tvalid_1's rmse: 0.081495\n",
      "[7000]\ttraining's rmse: 0.0704481\tvalid_1's rmse: 0.0797976\n",
      "[8000]\ttraining's rmse: 0.0691189\tvalid_1's rmse: 0.0784812\n",
      "[9000]\ttraining's rmse: 0.0679746\tvalid_1's rmse: 0.0773612\n",
      "[10000]\ttraining's rmse: 0.0669611\tvalid_1's rmse: 0.0764462\n",
      "[11000]\ttraining's rmse: 0.0660637\tvalid_1's rmse: 0.0754559\n",
      "[12000]\ttraining's rmse: 0.0652538\tvalid_1's rmse: 0.074449\n",
      "[13000]\ttraining's rmse: 0.064501\tvalid_1's rmse: 0.0735393\n",
      "[14000]\ttraining's rmse: 0.0638064\tvalid_1's rmse: 0.0728309\n",
      "[15000]\ttraining's rmse: 0.0631782\tvalid_1's rmse: 0.0721628\n",
      "[16000]\ttraining's rmse: 0.062586\tvalid_1's rmse: 0.0716169\n",
      "[17000]\ttraining's rmse: 0.0620231\tvalid_1's rmse: 0.0710673\n",
      "[18000]\ttraining's rmse: 0.0614993\tvalid_1's rmse: 0.0705554\n",
      "[19000]\ttraining's rmse: 0.0610064\tvalid_1's rmse: 0.0701055\n",
      "[20000]\ttraining's rmse: 0.0605355\tvalid_1's rmse: 0.0697037\n",
      "[21000]\ttraining's rmse: 0.0600838\tvalid_1's rmse: 0.0693015\n",
      "[22000]\ttraining's rmse: 0.0596486\tvalid_1's rmse: 0.0688946\n",
      "Early stopping, best iteration is:\n",
      "[22030]\ttraining's rmse: 0.059636\tvalid_1's rmse: 0.0688768\n",
      "Full rmse score 18336098.037621\n",
      "\n"
     ]
    }
   ],
   "source": [
    "oof_preds = np.zeros(x_valid.shape[0])\n",
    "sub_preds = np.zeros(x_test.shape[0])\n",
    "\n",
    "start = time.time()\n",
    "valid_score = 0\n",
    "\n",
    "feature_importance_df = pd.DataFrame()\n",
    "\n",
    "trn_x, trn_y = x_train[train_features], y_train\n",
    "val_x, val_y = x_valid[train_features], y_valid\n",
    "\n",
    "train_data = lgb.Dataset(data=trn_x, label=trn_y)\n",
    "valid_data = lgb.Dataset(data=val_x, label=val_y)   \n",
    "\n",
    "params = {\"objective\" : \"regression\", \"metric\" : \"rmse\", 'n_estimators':50000, 'early_stopping_rounds':125,\n",
    "                  \"num_leaves\" : 30, \"learning_rate\" : 0.016, \"bagging_fraction\" : 0.9,\n",
    "                   \"bagging_seed\" : 0}\n",
    "\n",
    "lgb_model = lgb.train(params, train_data, valid_sets=[train_data, valid_data], verbose_eval=1000) \n",
    "\n",
    "oof_preds = lgb_model.predict(val_x, num_iteration=lgb_model.best_iteration)\n",
    "sub_pred = lgb_model.predict(x_test, num_iteration=lgb_model.best_iteration) \n",
    "sub_preds = sub_pred \n",
    "\n",
    "    #print('Fold %2d rmse : %.6f' % (n_fold + 1, np.sqrt(mean_squared_error(val_y, oof_preds[val_idx]))))\n",
    "valid_score = mean_squared_error(val_y, oof_preds)\n",
    "\n",
    "fold_importance_df = pd.DataFrame()\n",
    "fold_importance_df[\"feature\"] = train_features\n",
    "fold_importance_df[\"importance\"] = lgb_model.feature_importance()\n",
    "feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "print('Full rmse score %.6f\\n' % np.sqrt(mean_squared_error(np.expm1(y_valid), np.expm1(oof_preds))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_valid['transaction_real_price'] = oof_preds\n",
    "x_valid['key'] = x_valid_key\n",
    "x_valid = x_valid[['key','transaction_real_price']]\n",
    "\n",
    "x_valid.to_csv(\"LGB_Testfile_LB5150_busan_valid_LV.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test['transaction_real_price'] = sub_preds\n",
    "x_test['key'] = busan_key\n",
    "x_test.to_csv(\"LGB_Testfile_LB5150_busan_test_LV.csv\",index=False)\n",
    "\n",
    "sub_busan_not = x_test[['key','transaction_real_price']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 서울"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "seoul_val_idx = df_train_seoul.groupby(['apartment_id']).tail(1).index\n",
    "seoul_trx_idx = set(df_train_seoul.index).difference(seoul_val_idx)\n",
    "seoul_train = df_train_seoul.loc[seoul_trx_idx,:]\n",
    "seoul_valid = df_train_seoul.loc[seoul_val_idx,:]\n",
    "\n",
    "seoul_train = seoul_train.sort_values('index')\n",
    "seoul_valid = seoul_valid.sort_values('index')\n",
    "df_test_seoul = df_test_seoul.sort_values('index')\n",
    "\n",
    "import time\n",
    "\n",
    "y_train = seoul_train['transaction_real_price'].reset_index(drop=True)\n",
    "\n",
    "x_train = seoul_train.copy().reset_index(drop=True)\n",
    "del x_train['city']; del x_train['transaction_real_price']; del x_train['key'];  del x_train['ica_1']\n",
    "\n",
    "excluded_features = ['key','index']\n",
    "train_features = [_f for _f in x_train.columns if _f not in excluded_features]\n",
    "\n",
    "y_valid = seoul_valid['transaction_real_price'].reset_index(drop=True)\n",
    "\n",
    "x_valid = seoul_valid.copy().reset_index(drop=True)\n",
    "x_valid_key = x_valid['key'].values\n",
    "del x_valid['city']; del x_valid['transaction_real_price']; del x_valid['key']; del x_valid['ica_1']\n",
    "\n",
    "seoul_key = df_test_seoul['key'].values\n",
    "x_test = df_test_seoul[train_features].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 125 rounds.\n",
      "[1000]\ttraining's rmse: 0.0690856\tvalid_1's rmse: 0.0771424\n",
      "[2000]\ttraining's rmse: 0.0621533\tvalid_1's rmse: 0.0663221\n",
      "[3000]\ttraining's rmse: 0.0584456\tvalid_1's rmse: 0.0596813\n",
      "[4000]\ttraining's rmse: 0.0559001\tvalid_1's rmse: 0.0556213\n",
      "[5000]\ttraining's rmse: 0.0539285\tvalid_1's rmse: 0.052467\n",
      "[6000]\ttraining's rmse: 0.0523089\tvalid_1's rmse: 0.0499012\n",
      "[7000]\ttraining's rmse: 0.0508973\tvalid_1's rmse: 0.0479889\n",
      "[8000]\ttraining's rmse: 0.0496604\tvalid_1's rmse: 0.0464096\n",
      "[9000]\ttraining's rmse: 0.0485713\tvalid_1's rmse: 0.045119\n",
      "[10000]\ttraining's rmse: 0.0475866\tvalid_1's rmse: 0.0438229\n",
      "[11000]\ttraining's rmse: 0.0466468\tvalid_1's rmse: 0.0426761\n",
      "[12000]\ttraining's rmse: 0.045812\tvalid_1's rmse: 0.0417601\n",
      "[13000]\ttraining's rmse: 0.0450043\tvalid_1's rmse: 0.040938\n",
      "[14000]\ttraining's rmse: 0.044263\tvalid_1's rmse: 0.0402414\n",
      "[15000]\ttraining's rmse: 0.0435732\tvalid_1's rmse: 0.0395608\n",
      "[16000]\ttraining's rmse: 0.0429163\tvalid_1's rmse: 0.0389311\n",
      "[17000]\ttraining's rmse: 0.0422919\tvalid_1's rmse: 0.0384248\n",
      "[18000]\ttraining's rmse: 0.0416869\tvalid_1's rmse: 0.0379387\n",
      "[19000]\ttraining's rmse: 0.0410994\tvalid_1's rmse: 0.0374184\n",
      "[20000]\ttraining's rmse: 0.0405535\tvalid_1's rmse: 0.0369548\n",
      "[21000]\ttraining's rmse: 0.0400287\tvalid_1's rmse: 0.0365622\n",
      "[22000]\ttraining's rmse: 0.0395142\tvalid_1's rmse: 0.036198\n",
      "[23000]\ttraining's rmse: 0.0390115\tvalid_1's rmse: 0.035957\n",
      "[24000]\ttraining's rmse: 0.038546\tvalid_1's rmse: 0.0356066\n",
      "[25000]\ttraining's rmse: 0.0380972\tvalid_1's rmse: 0.035345\n",
      "Early stopping, best iteration is:\n",
      "[25815]\ttraining's rmse: 0.0377395\tvalid_1's rmse: 0.0351376\n",
      "Full rmse score 29344525.158187\n",
      "\n"
     ]
    }
   ],
   "source": [
    "oof_preds = np.zeros(x_valid.shape[0])\n",
    "sub_preds = np.zeros(x_test.shape[0])\n",
    "\n",
    "start = time.time()\n",
    "valid_score = 0\n",
    "\n",
    "feature_importance_df = pd.DataFrame()\n",
    "\n",
    "trn_x, trn_y = x_train[train_features], y_train\n",
    "val_x, val_y = x_valid[train_features], y_valid\n",
    "\n",
    "train_data = lgb.Dataset(data=trn_x, label=trn_y)\n",
    "valid_data = lgb.Dataset(data=val_x, label=val_y)   \n",
    "\n",
    "params = {\"objective\" : \"regression\", \"metric\" : \"rmse\", 'n_estimators':50000, 'early_stopping_rounds':125,\n",
    "                  \"num_leaves\" : 25, \"learning_rate\" : 0.11, \"bagging_fraction\" : 0.9,\n",
    "                   \"bagging_seed\" : 0, \"lambda_l1\" : 0.1}\n",
    "\n",
    "lgb_model = lgb.train(params, train_data, valid_sets=[train_data, valid_data], verbose_eval=1000) \n",
    "\n",
    "oof_preds = lgb_model.predict(val_x, num_iteration=lgb_model.best_iteration)\n",
    "sub_pred = lgb_model.predict(x_test, num_iteration=lgb_model.best_iteration) \n",
    "sub_preds = sub_pred \n",
    "\n",
    "    #print('Fold %2d rmse : %.6f' % (n_fold + 1, np.sqrt(mean_squared_error(val_y, oof_preds[val_idx]))))\n",
    "valid_score = mean_squared_error(val_y, oof_preds)\n",
    "\n",
    "fold_importance_df = pd.DataFrame()\n",
    "fold_importance_df[\"feature\"] = train_features\n",
    "fold_importance_df[\"importance\"] = lgb_model.feature_importance()\n",
    "feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "print('Full rmse score %.6f\\n' % np.sqrt(mean_squared_error(np.expm1(y_valid), np.expm1(oof_preds))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_valid['transaction_real_price'] = oof_preds\n",
    "x_valid['key'] = x_valid_key\n",
    "x_valid = x_valid[['key','transaction_real_price']]\n",
    "\n",
    "x_valid.to_csv(\"LGB_Testfile_LB5150_seoul_valid_LV.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test['transaction_real_price'] = sub_preds\n",
    "x_test['key'] = seoul_key\n",
    "\n",
    "x_test.to_csv(\"LGB_Testfile_LB5150_seoul_test_LV.csv\",index=False)\n",
    "sub_seoul = x_test[['key','transaction_real_price']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 제출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>transaction_real_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1253422</td>\n",
       "      <td>18.633868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1369751</td>\n",
       "      <td>18.786149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1389544</td>\n",
       "      <td>18.359986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1394472</td>\n",
       "      <td>19.804171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1395869</td>\n",
       "      <td>19.325865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       key  transaction_real_price\n",
       "0  1253422               18.633868\n",
       "1  1369751               18.786149\n",
       "2  1389544               18.359986\n",
       "3  1394472               19.804171\n",
       "4  1395869               19.325865"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = pd.concat([sub_busan_not,sub_seoul])\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['transaction_real_price'] = np.expm1(sub['transaction_real_price'])\n",
    "sub = sub.sort_values('key')\n",
    "sub = sub.reset_index(drop=True)\n",
    "sub.to_csv(\"LGB_Testfile_LB5150_LV.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
